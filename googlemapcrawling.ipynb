{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#hdtb-msb-vis > div:nth-child(5) > a\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "\n",
    "word = \"마드리드 맛집\"\n",
    "'''\n",
    "# 번역부분---------\n",
    "import requests\n",
    "\n",
    "def kor2eng(query):\n",
    "    url = \"https://translate.kakao.com/translator/translate.json\"\n",
    "\n",
    "    headers = {\n",
    "        \"Referer\": \"https://translate.kakao.com/\",\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"queryLanguage\": \"ko\",\n",
    "        \"resultLanguage\": \"es\",\n",
    "        \"q\": query\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, data=data)\n",
    "    data = resp.json()\n",
    "    output = data['result']['output'][0][0]\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     print(kor2eng(\"コロナ19に注意してください。\"))\n",
    "    tword=kor2eng(word)\n",
    "    print(kor2eng(word))\n",
    "'''    \n",
    "#----------------------------\n",
    "\n",
    "def google_searching(word):\n",
    "    url = \"http://www.google.com/maps/search/\" + word\n",
    "    return url\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('C:/work/chromedriver')\n",
    "\n",
    "# 구글 접속하기\n",
    "driver.get('http://www.google.com/maps')\n",
    "time.sleep(3)\n",
    "print(1)\n",
    "\n",
    "#검색 후 목록 보기 \n",
    "url = google_searching(word)\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "results = []\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for i in range(20):\n",
    "    #목록에서 선택하기\n",
    "    def select_first(driver):\n",
    "        #pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(1) > div.section-result-content > div.section-result-text-content > div.section-result-header-container\n",
    "        first = driver.find_elements_by_css_selector(\"div.section-result\")[i]\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "    #         #first = soup.select('div.section-result-title-container > h3')[2]\n",
    "        global title\n",
    "        title = soup.select('div.section-result-title-container > h3')[0].text\n",
    "        print(title)\n",
    "        #print(first)\n",
    "        first.click()\n",
    "        time.sleep(3)\n",
    "    select_first(driver)\n",
    "    print('2')\n",
    "\n",
    "    #리뷰로 넘어가기\n",
    "    def select_second(driver):\n",
    "        second = driver.find_element_by_css_selector(\"span button\")\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        #ugiz4pqJLAG__primary-text gm2-body-2\n",
    "        global juso\n",
    "        juso = driver.find_element_by_css_selector('div.ugiz4pqJLAG__text').text\n",
    "        #juso = soup.select('div.ugiz4pqJLAG__text').text\n",
    "        print(juso)\n",
    "        second.click()\n",
    "        time.sleep(3)\n",
    "        #print(second)\n",
    "    time.sleep(3)    \n",
    "    select_second(driver)\n",
    "    print('3')\n",
    "\n",
    "    # 반복문 돌려서 리뷰 얻기.\n",
    "\n",
    "\n",
    "    def get_content(driver):\n",
    "        #  현재 페이지 html 정보 가져오기\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        # 총 별점 가져오기\n",
    "        tstar = soup.select('div.gm2-display-2')[0].text \n",
    "        print(tstar)\n",
    "\n",
    "        t = 0\n",
    "        s = 0\n",
    "        e = 8\n",
    "        while(t<20):\n",
    "            time.sleep(5)\n",
    "            if t == 0:\n",
    "                s = 0\n",
    "                e = 8\n",
    "            else:\n",
    "                s = 10 * (t-1) + 8\n",
    "                e = s + 10\n",
    "            for k in range(s, e):        \n",
    "                #  리뷰 내용 가져오기\n",
    "                try:\n",
    "                    #time.sleep(1)\n",
    "                    global content\n",
    "                    #content = soup.select('div.section-review')[t].text\n",
    "    #                 content = soup.select('div.section-review-review-content')[k].text\n",
    "                    content = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content'.format(3 * k + 1)).text\n",
    "    #                 print(content)\n",
    "\n",
    "                    #  리뷰 내용이 길 경우 자세히 버튼 눌러서 가져오기\n",
    "                    more = '자세히'\n",
    "                    if more in content:\n",
    "                        more.click()\n",
    "                        content = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content'.format(3 * k + 1)).text\n",
    "                        time.sleep(3)\n",
    "    #                     print(content)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print('err : ', e)\n",
    "                    #content = ' '\n",
    "\n",
    "                # 작성일 가져오기\n",
    "                date = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-publish-date'.format(3 * k + 1)).text\n",
    "    #             date = soup.select('span.section-review-publish-date')[k].text\n",
    "    #             print(date)\n",
    "\n",
    "                # 리뷰에서 별점 가져오기\n",
    "                try:\n",
    "                    #star = driver.find_element_by_css_selector('span.section-review-stars')\n",
    "                    global star\n",
    "                    star = int(''.join(re.findall(\"\\d+\", driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-stars'.format(3 * k + 1))\n",
    "                                                  .get_attribute('aria-label'))))\n",
    "    #                 star = soup.select('span.section-review-stars')[k]['aria-label']\n",
    "                    print(star)   \n",
    "                except:\n",
    "                    print('별점 에러')\n",
    "\n",
    "\n",
    "                data = [title, juso, content, date, star]\n",
    "    #             print(data)\n",
    "                results.append(data)\n",
    "            t += 1\n",
    "\n",
    "            # 스크롤\n",
    "\n",
    "            time.sleep(7)\n",
    "            scrollable_div = driver.find_element_by_css_selector(\n",
    "     'div.section-layout.section-scrollbox.scrollable-y.scrollable-show'\n",
    "                         )\n",
    "            driver.execute_script(\n",
    "                   'arguments[0].scrollTop = arguments[0].scrollHeight', \n",
    "                    scrollable_div\n",
    "                   )\n",
    "\n",
    "\n",
    "\n",
    "    get_content(driver)\n",
    "    # print(results)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['title', 'juso','content','date','star']\n",
    "results_df.to_excel('C:\\work\\madrid.xlsx')\n",
    "print('저장완료')\n",
    "driver.quit()\n",
    "\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(1)\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "멘쇼우라멘\n",
      "2\n",
      "서울특별시 관악구 낙성대동 남부순환로230길 25\n",
      "s1\n",
      "(153)\n",
      "3\n",
      "4.2\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "err :  Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child(460) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content\"}\n",
      "  (Session info: chrome=87.0.4280.88)\n",
      "\n"
     ]
    },
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child(460) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-publish-date\"}\n  (Session info: chrome=87.0.4280.88)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-a789c025b643>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m \u001b[0mget_content\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m     \u001b[1;31m# print(results)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-a789c025b643>\u001b[0m in \u001b[0;36mget_content\u001b[1;34m(driver)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;31m# 작성일 가져오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-publish-date'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;31m#             date = soup.select('span.section-review-publish-date')[k].text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;31m#             print(date)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_css_selector\u001b[1;34m(self, css_selector)\u001b[0m\n\u001b[0;32m    596\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'#foo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \"\"\"\n\u001b[1;32m--> 598\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcss_selector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcss_selector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mby\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCSS_SELECTOR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child(460) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-publish-date\"}\n  (Session info: chrome=87.0.4280.88)\n"
     ]
    }
   ],
   "source": [
    "#hdtb-msb-vis > div:nth-child(5) > a\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "\n",
    "word = \"이치란\"\n",
    "'''\n",
    "# 번역부분---------\n",
    "import requests\n",
    "\n",
    "def kor2eng(query):\n",
    "    url = \"https://translate.kakao.com/translator/translate.json\"\n",
    "\n",
    "    headers = {\n",
    "        \"Referer\": \"https://translate.kakao.com/\",\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"queryLanguage\": \"ko\",\n",
    "        \"resultLanguage\": \"es\",\n",
    "        \"q\": query\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, data=data)\n",
    "    data = resp.json()\n",
    "    output = data['result']['output'][0][0]\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     print(kor2eng(\"コロナ19に注意してください。\"))\n",
    "    tword=kor2eng(word)\n",
    "    print(kor2eng(word))\n",
    "'''    \n",
    "#----------------------------\n",
    "\n",
    "def google_searching(word):\n",
    "    url = \"http://www.google.com/maps/search/\" + word\n",
    "    return url\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('C:/work/chromedriver')\n",
    "\n",
    "# 구글 접속하기\n",
    "driver.get('http://www.google.com/maps')\n",
    "time.sleep(3)\n",
    "print(1)\n",
    "\n",
    "#검색 후 목록 보기 \n",
    "url = google_searching(word)\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "results = []\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#목록에서 선택하기\n",
    "def select_first(driver):\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        #pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(1) > div.section-result-content > div.section-result-text-content > div.section-result-header-container\n",
    "        first = driver.find_elements_by_css_selector(\"div.section-result\")[0]\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "            #first = soup.select('div.section-result-title-container > h3')[2]\n",
    "#         global title\n",
    "\n",
    "        title = soup.select('div.section-result-title-container > h3')[0].text\n",
    "        print(title)\n",
    "        #print(first)\n",
    "        first.click()\n",
    "    except:\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "#         global title\n",
    "\n",
    "        title = soup.select('h1.section-hero-header-title-title.GLOBAL__gm2-headline-5 > span')[0].text\n",
    "        print(title)\n",
    "        \n",
    "    time.sleep(3)\n",
    "select_first(driver)\n",
    "print('2')\n",
    "\n",
    "#리뷰로 넘어가기\n",
    "def select_second(driver):\n",
    "    driver.refresh()\n",
    "    time.sleep(5)\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    #ugiz4pqJLAG__primary-text gm2-body-2\n",
    "    global juso\n",
    "    juso = driver.find_element_by_css_selector('div.ugiz4pqJLAG__text').text\n",
    "    #juso = soup.select('div.ugiz4pqJLAG__text').text\n",
    "    print(juso)\n",
    "    try:\n",
    "        second = driver.find_element_by_css_selector(\"button.widget-pane-link\")\n",
    "        print('s1')\n",
    "        print(second.text)\n",
    "        second.click()\n",
    "    except:\n",
    "        second = driver.find_element_by_css_selector(\"button.gm2-button-alt.jqnFjrOWMVU__button-blue\")\n",
    "        print('s2')\n",
    "        print(second.text)\n",
    "        second.click()\n",
    "#         button.gm2-button-alt.jqnFjrOWMVU__button-blue\n",
    "    \n",
    "    time.sleep(3)\n",
    "    #print(second)\n",
    "time.sleep(3)    \n",
    "select_second(driver)\n",
    "print('3')\n",
    "\n",
    "# 반복문 돌려서 리뷰 얻기.\n",
    "\n",
    "\n",
    "def get_content(driver):\n",
    "    #  현재 페이지 html 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    # 총 별점 가져오기\n",
    "    tstar = soup.select('div.gm2-display-2')[0].text \n",
    "    print(tstar)\n",
    "\n",
    "    t = 0\n",
    "    s = 0\n",
    "    e = 8\n",
    "    while(t<20):\n",
    "        time.sleep(5)\n",
    "        if t == 0:\n",
    "            s = 0\n",
    "            e = 8\n",
    "        else:\n",
    "            s = 10 * (t-1) + 8\n",
    "            e = s + 10\n",
    "        for k in range(s, e):        \n",
    "            #  리뷰 내용 가져오기\n",
    "            try:\n",
    "                #time.sleep(1)\n",
    "                global content\n",
    "                #content = soup.select('div.section-review')[t].text\n",
    "#                 content = soup.select('div.section-review-review-content')[k].text\n",
    "                content = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content'.format(3 * k + 1)).text\n",
    "#                 print(content)\n",
    "\n",
    "                #  리뷰 내용이 길 경우 자세히 버튼 눌러서 가져오기\n",
    "                more = '자세히'\n",
    "                if more in content:\n",
    "                    more.click()\n",
    "                    content = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content'.format(3 * k + 1)).text\n",
    "                    time.sleep(3)\n",
    "#                     print(content)\n",
    "\n",
    "            except Exception as e:\n",
    "                print('err : ', e)\n",
    "                #content = ' '\n",
    "\n",
    "            # 작성일 가져오기\n",
    "            date = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-publish-date'.format(3 * k + 1)).text\n",
    "#             date = soup.select('span.section-review-publish-date')[k].text\n",
    "#             print(date)\n",
    "\n",
    "            # 리뷰에서 별점 가져오기\n",
    "            try:\n",
    "                #star = driver.find_element_by_css_selector('span.section-review-stars')\n",
    "                global star\n",
    "                star = int(''.join(re.findall(\"\\d+\", driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-stars'.format(3 * k + 1))\n",
    "                                              .get_attribute('aria-label'))))\n",
    "#                 star = soup.select('span.section-review-stars')[k]['aria-label']\n",
    "                print(별)   \n",
    "            except:\n",
    "                print('별점 에러')\n",
    "\n",
    "\n",
    "            data = [title, juso, content, date, star]\n",
    "#             print(data)\n",
    "            results.append(data)\n",
    "        t += 1\n",
    "\n",
    "        # 스크롤\n",
    "\n",
    "        try:\n",
    "            time.sleep(7)\n",
    "            scrollable_div = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show')\n",
    "            driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "        except:\n",
    "            break\n",
    "\n",
    "\n",
    "get_content(driver)\n",
    "    # print(results)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['title', 'juso','content','date','star']\n",
    "results_df.to_excel('C:\\work\\madrid.xlsx')\n",
    "print('저장완료')\n",
    "driver.quit()\n",
    "\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(1)\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(3)\n",
    "\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.jqnFjrOWMVU__root > div > div.jqnFjrOWMVU__right > button\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div:nth-child(45) > div > div > button\n",
    "\n",
    "# span.reviews-tap-area.reviews-tap-area-enabled > span:nth-child(1) > button\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-hero-header-title > div.section-hero-header-title-top-container > div.section-hero-header-title-description > div.section-hero-header-title-description-container > div > div.gm2-body-2.section-rating-line > span:nth-child(3) > span > span.section-rating-term > span:nth-child(2) > span:nth-child(1) > span\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.jqnFjrOWMVU__root > div > div.jqnFjrOWMVU__right > button.gm2-button-alt.jqnFjrOWMVU__button-blue\n",
    "\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child(22) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-publish-date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "51//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdtb-msb-vis > div:nth-child(5) > a\n",
    "def googlemapfunc(searchtext):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    from selenium import webdriver as wd\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    import time\n",
    "    import re\n",
    "    import os\n",
    "    import sys\n",
    "    import urllib.request\n",
    "    import datetime\n",
    "    import pandas as pd\n",
    "\n",
    "    word = searchtext\n",
    "    '''\n",
    "    # 번역부분---------\n",
    "    import requests\n",
    "\n",
    "    def kor2eng(query):\n",
    "        url = \"https://translate.kakao.com/translator/translate.json\"\n",
    "\n",
    "        headers = {\n",
    "            \"Referer\": \"https://translate.kakao.com/\",\n",
    "            \"User-Agent\": \"Mozilla/5.0\"\n",
    "        }\n",
    "\n",
    "        data = {\n",
    "            \"queryLanguage\": \"ko\",\n",
    "            \"resultLanguage\": \"es\",\n",
    "            \"q\": query\n",
    "        }\n",
    "\n",
    "        resp = requests.post(url, headers=headers, data=data)\n",
    "        data = resp.json()\n",
    "        output = data['result']['output'][0][0]\n",
    "        return output\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "    #     print(kor2eng(\"コロナ19に注意してください。\"))\n",
    "        tword=kor2eng(word)\n",
    "        print(kor2eng(word))\n",
    "    '''    \n",
    "    #----------------------------\n",
    "\n",
    "    def google_searching(word):\n",
    "        url = \"http://www.google.com/maps/search/\" + word\n",
    "        return url\n",
    "\n",
    "    from selenium import webdriver\n",
    "\n",
    "\n",
    "    driver = webdriver.Chrome('C:/work/chromedriver')\n",
    "\n",
    "    # 구글 접속하기\n",
    "    driver.get('http://www.google.com/maps')\n",
    "    time.sleep(3)\n",
    "    print(1)\n",
    "\n",
    "    #검색 후 목록 보기 \n",
    "    url = google_searching(word)\n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    import re\n",
    "    from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "    #목록에서 선택하기\n",
    "    def select_first(driver,idx):\n",
    "        n = 0\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            #pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(1) > div.section-result-content > div.section-result-text-content > div.section-result-header-container\n",
    "            first = driver.find_elements_by_css_selector(\"div.section-result\")[idx]\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "                #first = soup.select('div.section-result-title-container > h3')[2]\n",
    "    #         global title\n",
    "\n",
    "            title = soup.select('div.section-result-title-container > h3')[0].text\n",
    "            print(title)\n",
    "            #print(first)\n",
    "            first.click()\n",
    "        except:\n",
    "            if idx != 0:\n",
    "                results_df = pd.DataFrame(results)\n",
    "                results_df.columns = ['title', 'juso','content','date','star']\n",
    "                results_df.to_excel('C:\\work\\{}.xlsx'.format(word))\n",
    "                print('저장완료')\n",
    "                driver.quit()\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'lxml')\n",
    "    #         global title\n",
    "\n",
    "            title = soup.select('h1.section-hero-header-title-title.GLOBAL__gm2-headline-5 > span')[0].text\n",
    "            print(title)\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        print('2')\n",
    "\n",
    "        #리뷰로 넘어가기\n",
    "\n",
    "        driver.refresh()\n",
    "        time.sleep(8)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        #ugiz4pqJLAG__primary-text gm2-body-2\n",
    "        global juso\n",
    "        juso = driver.find_element_by_css_selector('div.ugiz4pqJLAG__text').text\n",
    "        #juso = soup.select('div.ugiz4pqJLAG__text').text\n",
    "        print(juso)\n",
    "        try:\n",
    "            second = driver.find_element_by_css_selector(\"button.widget-pane-link\")\n",
    "            print('s1')\n",
    "            n = int(''.join(re.findall(\"\\d+\", second.text))) // 10\n",
    "            print(second.text)\n",
    "            second.click()\n",
    "        except:\n",
    "            second = driver.find_element_by_css_selector(\"button.gm2-button-alt.jqnFjrOWMVU__button-blue\")\n",
    "            print('s2')\n",
    "            n = int(''.join(re.findall(\"\\d+\", second.text))) // 10\n",
    "            print(second.text)\n",
    "            second.click()\n",
    "        #         button.gm2-button-alt.jqnFjrOWMVU__button-blue\n",
    "\n",
    "        time.sleep(5)\n",
    "        print('3')\n",
    "\n",
    "        # 반복문 돌려서 리뷰 얻기.\n",
    "\n",
    "\n",
    "\n",
    "        #  현재 페이지 html 정보 가져오기\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "        # 총 별점 가져오기\n",
    "        tstar = soup.select('div.gm2-display-2')[0].text \n",
    "        print(tstar)\n",
    "        if n > 15:\n",
    "            n = 15\n",
    "        t = 0\n",
    "        s = 0\n",
    "        e = 8\n",
    "        while(t<n):\n",
    "            time.sleep(5)\n",
    "            if t == 0:\n",
    "                s = 0\n",
    "                e = 8\n",
    "            else:\n",
    "                s = 10 * (t-1) + 8\n",
    "                e = s + 10\n",
    "            for k in range(s, e):        \n",
    "                #  리뷰 내용 가져오기\n",
    "                try:\n",
    "                    #time.sleep(1)\n",
    "                    global content\n",
    "                    content = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content'.format(3 * k + 1)).text\n",
    "        #                 print(content)\n",
    "\n",
    "                    #  리뷰 내용이 길 경우 자세히 버튼 눌러서 가져오기\n",
    "                    more = '자세히'\n",
    "                    if more in content:\n",
    "                        more.click()\n",
    "                        content = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content'.format(3 * k + 1)).text\n",
    "                        time.sleep(3)\n",
    "        #                     print(content)\n",
    "                    # 작성일 가져오기\n",
    "                    date = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-publish-date'.format(3 * k + 1)).text\n",
    "            #             date = soup.select('span.section-review-publish-date')[k].text\n",
    "            #             print(date)\n",
    "\n",
    "                    # 리뷰에서 별점 가져오기\n",
    "                    try:\n",
    "                        #star = driver.find_element_by_css_selector('span.section-review-stars')\n",
    "                        global star\n",
    "                        star = int(''.join(re.findall(\"\\d+\", driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-stars'.format(3 * k + 1))\n",
    "                                                      .get_attribute('aria-label'))))\n",
    "            #                 star = soup.select('span.section-review-stars')[k]['aria-label']\n",
    "                        print(star)   \n",
    "                    except:\n",
    "                        print('별점 에러')\n",
    "\n",
    "                    data = [title, juso, content, date, star]\n",
    "            #             print(data)\n",
    "                    results.append(data)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print('err : ', e)\n",
    "                    return\n",
    "\n",
    "            t += 1\n",
    "\n",
    "            # 스크롤\n",
    "\n",
    "            try:\n",
    "                time.sleep(7)\n",
    "                scrollable_div = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show')\n",
    "                driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "            except:\n",
    "                break\n",
    "\n",
    "    for i in range(5):\n",
    "        select_first(driver, i)\n",
    "        driver.refresh()\n",
    "        time.sleep(5)\n",
    "        back = driver.find_element_by_css_selector(\"button.ozj7Vb3wnYq__action-button-clickable\")\n",
    "        back.click()\n",
    "        time.sleep(5)\n",
    "        try:\n",
    "            back2 = driver.find_element_by_css_selector(\"button.section-back-to-list-button.blue-link.noprint\")\n",
    "            back2.click()\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.columns = ['title', 'juso','content','date','star']\n",
    "    results_df.to_excel('C:\\work\\{}.xlsx'.format(word))\n",
    "    print('저장완료')\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "야마야 이마주쿠점\n",
      "2\n",
      "3 Chome-40-1 Imajuku, Nishi Ward, Fukuoka, 819-0167 일본\n",
      "s1\n",
      "(123)\n",
      "3\n",
      "3.8\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Yamaya\n",
      "2\n",
      "2 Chome-2-13 Akine Nishimachi, Shimonoseki, Yamaguchi 751-0873 일본\n",
      "s1\n",
      "(59)\n",
      "3\n",
      "3.7\n",
      "5\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "1\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "Yamaya Koga\n",
      "2\n",
      "3 Chome-1-44 Chiko, Nogata, Fukuoka 822-0022 일본\n",
      "s1\n",
      "(66)\n",
      "3\n",
      "4.0\n",
      "err :  Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\"div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child(1) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content\"}\n",
      "  (Session info: chrome=87.0.4280.88)\n",
      "\n",
      "Yamaya Koga\n",
      "2\n",
      "3 Chome-40-1 Imajuku, Nishi Ward, Fukuoka, 819-0167 일본\n",
      "s1\n",
      "(123)\n",
      "3\n",
      "3.8\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "야마야 이마주쿠점\n",
      "2\n",
      "3 Chome-15-1 Mainosato, Koga, Fukuoka 811-3114 일본\n",
      "s1\n",
      "(211)\n",
      "3\n",
      "3.8\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "1\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "3\n",
      "저장완료\n"
     ]
    }
   ],
   "source": [
    "googlemapfunc('やまや')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "멘쇼우라멘\n",
      "2\n",
      "서울특별시 관악구 낙성대동 남부순환로230길 25\n",
      "s1\n",
      "(153)\n",
      "3\n",
      "4.2\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n",
      "별점 에러\n"
     ]
    }
   ],
   "source": [
    "#hdtb-msb-vis > div:nth-child(5) > a\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "word = \"이치란\"\n",
    "'''\n",
    "# 번역부분---------\n",
    "import requests\n",
    "\n",
    "def kor2eng(query):\n",
    "    url = \"https://translate.kakao.com/translator/translate.json\"\n",
    "\n",
    "    headers = {\n",
    "        \"Referer\": \"https://translate.kakao.com/\",\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"queryLanguage\": \"ko\",\n",
    "        \"resultLanguage\": \"es\",\n",
    "        \"q\": query\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, data=data)\n",
    "    data = resp.json()\n",
    "    output = data['result']['output'][0][0]\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     print(kor2eng(\"コロナ19に注意してください。\"))\n",
    "    tword=kor2eng(word)\n",
    "    print(kor2eng(word))\n",
    "'''    \n",
    "#----------------------------\n",
    "\n",
    "def google_searching(word):\n",
    "    url = \"http://www.google.com/maps/search/\" + word\n",
    "    return url\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('C:/work/chromedriver')\n",
    "\n",
    "# 구글 접속하기\n",
    "driver.get('http://www.google.com/maps')\n",
    "time.sleep(3)\n",
    "print(1)\n",
    "\n",
    "#검색 후 목록 보기 \n",
    "url = google_searching(word)\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "\n",
    "results = []\n",
    "n = 0\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "time.sleep(3)\n",
    "try:\n",
    "    #pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(1) > div.section-result-content > div.section-result-text-content > div.section-result-header-container\n",
    "    first = driver.find_elements_by_css_selector(\"div.section-result\")[0]\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "        #first = soup.select('div.section-result-title-container > h3')[2]\n",
    "#         global title\n",
    "\n",
    "    title = soup.select('div.section-result-title-container > h3')[0].text\n",
    "    print(title)\n",
    "    #print(first)\n",
    "    first.click()\n",
    "except:\n",
    "    if 0 != 0:\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df.columns = ['title', 'juso','content','date','star']\n",
    "        results_df.to_excel('C:\\work\\{}.xlsx'.format(word))\n",
    "        print('저장완료')\n",
    "        driver.quit()\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "#         global title\n",
    "\n",
    "    title = soup.select('h1.section-hero-header-title-title.GLOBAL__gm2-headline-5 > span')[0].text\n",
    "    print(title)\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "print('2')\n",
    "\n",
    "#리뷰로 넘어가기\n",
    "\n",
    "driver.refresh()\n",
    "time.sleep(5)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "#ugiz4pqJLAG__primary-text gm2-body-2\n",
    "global juso\n",
    "juso = driver.find_element_by_css_selector('div.ugiz4pqJLAG__text').text\n",
    "#juso = soup.select('div.ugiz4pqJLAG__text').text\n",
    "print(juso)\n",
    "try:\n",
    "    second = driver.find_element_by_css_selector(\"button.widget-pane-link\")\n",
    "    print('s1')\n",
    "    print(second.text)\n",
    "    second.click()\n",
    "except:\n",
    "    second = driver.find_element_by_css_selector(\"button.gm2-button-alt.jqnFjrOWMVU__button-blue\")\n",
    "    print('s2')\n",
    "    print(second.text)\n",
    "    second.click()\n",
    "#         button.gm2-button-alt.jqnFjrOWMVU__button-blue\n",
    "\n",
    "time.sleep(5)\n",
    "print('3')\n",
    "\n",
    "# 반복문 돌려서 리뷰 얻기.\n",
    "\n",
    "\n",
    "\n",
    "#  현재 페이지 html 정보 가져오기\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# 총 별점 가져오기\n",
    "tstar = soup.select('div.gm2-display-2')[0].text \n",
    "print(tstar)\n",
    "\n",
    "t = 0\n",
    "s = 0\n",
    "e = 8\n",
    "while(t<11):\n",
    "    time.sleep(5)\n",
    "    if t == 0:\n",
    "        s = 0\n",
    "        e = 8\n",
    "    else:\n",
    "        s = 10 * (t-1) + 8\n",
    "        e = s + 10\n",
    "    for k in range(s, e):        \n",
    "        #  리뷰 내용 가져오기\n",
    "        try:\n",
    "            #time.sleep(1)\n",
    "            global content\n",
    "            #content = soup.select('div.section-review')[t].text\n",
    "#                 content = soup.select('div.section-review-review-content')[k].text\n",
    "            content = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content'.format(3 * k + 1)).text\n",
    "#                 print(content)\n",
    "\n",
    "            #  리뷰 내용이 길 경우 자세히 버튼 눌러서 가져오기\n",
    "            more = '자세히'\n",
    "            if more in content:\n",
    "                more.click()\n",
    "                content = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-review-content'.format(3 * k + 1)).text\n",
    "                time.sleep(3)\n",
    "#                     print(content)\n",
    "            # 작성일 가져오기\n",
    "            date = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-publish-date'.format(3 * k + 1)).text\n",
    "    #             date = soup.select('span.section-review-publish-date')[k].text\n",
    "    #             print(date)\n",
    "\n",
    "            # 리뷰에서 별점 가져오기\n",
    "            try:\n",
    "                #star = driver.find_element_by_css_selector('span.section-review-stars')\n",
    "                global star\n",
    "                star = int(''.join(re.findall(\"\\d+\", driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-metadata.section-review-metadata-with-note > span.section-review-stars'.format(3 * k + 1))\n",
    "                                              .get_attribute('aria-label'))))\n",
    "    #                 star = soup.select('span.section-review-stars')[k]['aria-label']\n",
    "                print(별)   \n",
    "            except:\n",
    "                print('별점 에러')\n",
    "\n",
    "            data = [title, juso, content, date, star]\n",
    "    #             print(data)\n",
    "            results.append(data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('err : ', e)\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_df.columns = ['title', 'juso','content','date','star']\n",
    "            results_df.to_excel('C:\\work\\{}.xlsx'.format(word))\n",
    "            print('저장완료')\n",
    "            driver.quit()\n",
    "\n",
    "    t += 1\n",
    "\n",
    "    # 스크롤\n",
    "\n",
    "    try:\n",
    "        time.sleep(7)\n",
    "        scrollable_div = driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show')\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = driver.find_element_by_css_selector(\"button.ozj7Vb3wnYq__action-button-clickable\")\n",
    "back.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = driver.find_element_by_css_selector(\"button.section-back-to-list-button.blue-link.noprint\")\n",
    "back.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,606)\n"
     ]
    }
   ],
   "source": [
    "print(driver.find_element_by_css_selector(\"button.widget-pane-link\").text)\n",
    "driver.find_element_by_css_selector(\"button.widget-pane-link\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "\n",
    "word = \"도쿄 맛집\"\n",
    "'''\n",
    "# 번역부분---------\n",
    "import requests\n",
    "\n",
    "def kor2eng(query):\n",
    "    url = \"https://translate.kakao.com/translator/translate.json\"\n",
    "\n",
    "    headers = {\n",
    "        \"Referer\": \"https://translate.kakao.com/\",\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"queryLanguage\": \"ko\",\n",
    "        \"resultLanguage\": \"es\",\n",
    "        \"q\": query\n",
    "    }\n",
    "\n",
    "    resp = requests.post(url, headers=headers, data=data)\n",
    "    data = resp.json()\n",
    "    output = data['result']['output'][0][0]\n",
    "    return output\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     print(kor2eng(\"コロナ19に注意してください。\"))\n",
    "    tword=kor2eng(word)\n",
    "    print(kor2eng(word))\n",
    "'''    \n",
    "#----------------------------\n",
    "\n",
    "def google_searching(word):\n",
    "    url = \"http://www.google.com/maps/search/\" + word\n",
    "    return url\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('C:/work/chromedriver')\n",
    "\n",
    "# 구글 접속하기\n",
    "driver.get('http://www.google.com/maps')\n",
    "time.sleep(3)\n",
    "print(1)\n",
    "\n",
    "#검색 후 목록 보기 \n",
    "url = google_searching(word)\n",
    "driver.get(url)\n",
    "time.sleep(5)\n",
    "\n",
    "results = []\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#목록에서 선택하기\n",
    "def select_first(driver):\n",
    "    #pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(1) > div.section-result-content > div.section-result-text-content > div.section-result-header-container\n",
    "    first = driver.find_element_by_css_selector(\"div.section-result\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "#         #first = soup.select('div.section-result-title-container > h3')[2]\n",
    "    global title\n",
    "    title = soup.select('div.section-result-title-container > h3')[0].text\n",
    "    print(title)\n",
    "    #print(first)\n",
    "    first.click()\n",
    "    time.sleep(5)\n",
    "select_first(driver)\n",
    "print('2')\n",
    "\n",
    "#리뷰로 넘어가기\n",
    "def select_second(driver):\n",
    "    second = driver.find_element_by_css_selector(\"span button\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    #ugiz4pqJLAG__primary-text gm2-body-2\n",
    "    global juso\n",
    "    juso = driver.find_element_by_css_selector('div.ugiz4pqJLAG__text').text\n",
    "    #juso = soup.select('div.ugiz4pqJLAG__text').text\n",
    "    print(juso)\n",
    "    second.click()\n",
    "    time.sleep(5)\n",
    "    #print(second)\n",
    "select_second(driver)\n",
    "print('3')\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div:nth-child(47) > div > div > button\n",
    "\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.jqnFjrOWMVU__root > div > div.jqnFjrOWMVU__right > button\n",
    "\n",
    "# 반복문 돌려서 리뷰 얻기.\n",
    "\n",
    "\n",
    "def get_content(driver):\n",
    "    #  현재 페이지 html 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # 총 별점 가져오기\n",
    "    tstar = soup.select('div.gm2-display-2')[0].text \n",
    "    print(tstar)\n",
    "    \n",
    "    t = 0\n",
    "    s = 0\n",
    "    e = 8\n",
    "    while(t<200):\n",
    "        time.sleep(5)\n",
    "        if t == 0:\n",
    "            s = 0\n",
    "            e = 8\n",
    "        else:\n",
    "            s = 10 * (t-1) + 8\n",
    "            e = s + 10\n",
    "        for k in range(s, e):        \n",
    "            #  리뷰 내용 가져오기\n",
    "            try:\n",
    "                time.sleep(3)\n",
    "                global content\n",
    "                #content = soup.select('div.section-review')[t].text\n",
    "                content = soup.select('div.section-review-review-content')[t].text\n",
    "                print(content)\n",
    "            \n",
    "                #  리뷰 내용이 길 경우 자세히 버튼 눌러서 가져오기\n",
    "                more = '자세히'\n",
    "                if more in content:\n",
    "                    more.click()\n",
    "                    content = soup.select('div.section-review-review-content')[t].text\n",
    "                    time.sleep(3)\n",
    "                    print(content)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print('err : ', e)\n",
    "                #content = ' '\n",
    "            \n",
    "            # 작성일 가져오기\n",
    "            #date = driver.find_element_by_css_selector('span.section-review-publish-date').text\n",
    "            date = soup.select('span.section-review-publish-date')[1].text\n",
    "            print(date)\n",
    "            \n",
    "            # 리뷰에서 별점 가져오기\n",
    "            try:\n",
    "                #star = driver.find_element_by_css_selector('span.section-review-stars')\n",
    "                global star\n",
    "                star = soup.select('span.section-review-stars')[1]['aria-label']\n",
    "                print(별)   \n",
    "            except:\n",
    "                print('별점 에러')\n",
    "            \n",
    "#             print('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div.section-review-line.section-review-line-with-indent > div > button'.format(3 * k + 1))\n",
    "            print(k)\n",
    "#             driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div.section-review-line.section-review-line-with-indent > div > button'.format(3 * k + 1)).click()\n",
    "#             driver.find_element_by_css_selector('div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child({}) > div > div.section-review-content > div:nth-child(3) > div.section-review-interaction-bar.section-review-interaction-bar-after-photos > button:nth-child(3)'.format(3 * k + 1)).click()\n",
    "#             time.sleep(2)\n",
    "#             driver.find_element_by_css_selector('#modal-dialog-widget > div.modal-container > div > div.modal-close-row > button').click()\n",
    "            \n",
    "            #modal-dialog-widget > div.modal-container > div > div.modal-close-row > button\n",
    "            data = [title, juso, content, date, star]\n",
    "            print(data)\n",
    "            results.append(data)\n",
    "            \n",
    "        scrollable_div = driver.find_element_by_css_selector(\n",
    "            'div.section-layout.section-scrollbox.scrollable-y.scrollable-show'\n",
    "                 )\n",
    "        driver.execute_script(\n",
    "           'arguments[0].scrollTop = arguments[0].scrollHeight', \n",
    "            scrollable_div\n",
    "           )\n",
    "        t += 1\n",
    "          \n",
    "        # 스크롤\n",
    "        \n",
    "#         time.sleep(5)\n",
    "#         last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#         driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#         time.sleep(5)\n",
    "#         new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#         if new_height == last_height:\n",
    "#             driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "#             time.sleep(5)\n",
    "#             new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#             if new_height == last_height:\n",
    "#                 break\n",
    "\n",
    "#             else:\n",
    "#                 last_height = new_height\n",
    "#                 continue\n",
    "        \n",
    "     \n",
    "        \n",
    "get_content(driver)\n",
    "print(results)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['title', 'juso','content','date','star']\n",
    "results_df.to_excel('C:\\work\\madrid.xlsx')\n",
    "print('저장완료')\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"마드리드 맛집\"\n",
    "def google_searching(word):\n",
    "    url = \"http://www.google.com/maps/search/\" + word\n",
    "    return url\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome('C:/work/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구글 접속하기\n",
    "driver.get('http://www.google.com/maps')\n",
    "time.sleep(3)\n",
    "print(1)\n",
    "\n",
    "#검색 후 목록 보기 \n",
    "url = google_searching(word)\n",
    "driver.get(url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "#목록에서 선택하기\n",
    "def select_first(driver):\n",
    "    #pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div.section-layout.section-scrollbox.scrollable-y.scrollable-show.section-layout-flex-vertical > div:nth-child(1) > div.section-result-content > div.section-result-text-content > div.section-result-header-container\n",
    "    first = driver.find_element_by_css_selector(\"div.section-result\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "#         #first = soup.select('div.section-result-title-container > h3')[2]\n",
    "    global title\n",
    "    title = soup.select('div.section-result-title-container > h3')[0].text\n",
    "    print(title)\n",
    "    #print(first)\n",
    "    first.click()\n",
    "    time.sleep(3)\n",
    "select_first(driver)\n",
    "print('2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰로 넘어가기\n",
    "def select_second(driver):\n",
    "    second = driver.find_element_by_css_selector(\"span button\")\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    #ugiz4pqJLAG__primary-text gm2-body-2\n",
    "    global juso\n",
    "    juso = driver.find_element_by_css_selector('div.ugiz4pqJLAG__text').text\n",
    "    #juso = soup.select('div.ugiz4pqJLAG__text').text\n",
    "    print(juso)\n",
    "    second.click()\n",
    "    time.sleep(3)\n",
    "    #print(second)\n",
    "select_second(driver)\n",
    "print('3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복문 돌려서 리뷰 얻기.\n",
    "\n",
    "\n",
    "def get_content(driver):\n",
    "    #  현재 페이지 html 정보 가져오기\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    # 총 별점 가져오기\n",
    "    tstar = soup.select('div.gm2-display-2')[0].text \n",
    "    print(tstar)\n",
    "    \n",
    "    t = 0\n",
    "    while(t<200):\n",
    "        time.sleep(5)\n",
    "        for k in range(7 * t + 1, 7 * t + 8):        \n",
    "            #  리뷰 내용 가져오기\n",
    "            try:\n",
    "                #time.sleep(1)\n",
    "                global content\n",
    "                #content = soup.select('div.section-review')[t].text\n",
    "                content = soup.select('div.section-review-review-content')[t].text\n",
    "                print(content)\n",
    "            \n",
    "                #  리뷰 내용이 길 경우 자세히 버튼 눌러서 가져오기\n",
    "                more = '자세히'\n",
    "                if more in content:\n",
    "                    more.click()\n",
    "                    content = soup.select('div.section-review-review-content')[t].text\n",
    "                    time.sleep(3)\n",
    "                    print(content)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print('err : ', e)\n",
    "                #content = ' '\n",
    "            \n",
    "            # 작성일 가져오기\n",
    "            #date = driver.find_element_by_css_selector('span.section-review-publish-date').text\n",
    "            date = soup.select('span.section-review-publish-date')[t].text\n",
    "            print(date)\n",
    "            \n",
    "            # 리뷰에서 별점 가져오기\n",
    "            try:\n",
    "                #star = driver.find_element_by_css_selector('span.section-review-stars')\n",
    "                global star\n",
    "                star = soup.select('span.section-review-stars')[t]['aria-label']\n",
    "                print(별)   \n",
    "            except:\n",
    "                print('별점 에러')\n",
    "                \n",
    "            \n",
    "            data = [title, juso, content, date, star]\n",
    "            print(data)\n",
    "            results.append(data)\n",
    "            t += 1\n",
    "          \n",
    "        # 스크롤\n",
    "        \n",
    "        time.sleep(5)\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(5)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                last_height = new_height\n",
    "                continue\n",
    "        \n",
    "     \n",
    "        \n",
    "get_content(driver)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = ['title', 'juso','content','date','star']\n",
    "results_df.to_excel('C:\\work\\madrid.xlsx')\n",
    "print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            last_height = new_height\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show\n",
    "\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child(1) > div > div.section-review-content > div.section-review-line.section-review-line-with-indent > div > button > img\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child(4) > div > div.section-review-content > div.section-review-line.section-review-line-with-indent > div > button > img\n",
    "#pane > div > div.widget-pane-content.scrollable-y > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child(7) > div > div.section-review-content > div.section-review-line.section-review-line-with-indent > div > button > img\n",
    "#pane > div > div.widget-pane-content.scrollable-y.scrollable-show > div > div > div.section-layout.section-scrollbox.scrollable-y.scrollable-show > div:nth-child(9) > div:nth-child(85) > div > div.section-review-content > div.section-review-line.section-review-line-with-indent > div > button > img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys\n",
    "body = driver.find_element_by_css_selector('div')\n",
    "for i in range(10):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
